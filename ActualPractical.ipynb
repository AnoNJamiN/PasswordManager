{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553923cb-8c85-4377-b9c3-abecd31e4116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizeOfImage: 50x50\n",
      "Shape of tensor: torch.Size([4, 50, 50])\n",
      "Datatype of tensor: torch.uint8\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "#-----creating a dummy tensor-----#\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "image = Image.open('magic_lamp.png')\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "tensor = transform(image)\n",
    "print(f\"sizeOfImage:\",\"50x50\")\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ba996c-2ac4-467e-8c5a-e87d71429011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizeOfImage: 50x50\n",
      "Shape of tensor: torch.Size([4, 50, 50])\n",
      "Datatype of tensor: torch.uint8\n",
      "Device tensor is stored on: cpu\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=10000, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "#-----creating a dummy tensor-----#\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "image = Image.open('magic_lamp.png')\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "tensor = transform(image)\n",
    "print(f\"sizeOfImage:\",\"50x50\")\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(50*50*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dea6e78-8a07-4742-af57-e99e130213eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizeOfImage: 50x50\n",
      "Shape of tensor: torch.Size([4, 50, 50])\n",
      "Datatype of tensor: torch.float32\n",
      "Input->Output:   torch.Size([4, 50, 50])->torch.Size([1, 10])\n",
      "Output logits: tensor([[-0.0059, -0.0186,  0.0160,  0.0523, -0.0003,  0.0428,  0.0967, -0.0012,\n",
      "         -0.0351, -0.1542]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the image and convert to proper tensor format\n",
    "image = Image.open('magic_lamp.png')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((50, 50)),  # Ensure 50x50 size\n",
    "    transforms.ToTensor()  # Converts to float32 and normalizes to [0,1]\n",
    "])\n",
    "dummy_tensor = transform(image)\n",
    "\n",
    "print(f\"sizeOfImage: 50x50\")\n",
    "print(f\"Shape of tensor: {dummy_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {dummy_tensor.dtype}\")\n",
    "#print(f\"Device tensor is stored on: {dummy_tensor.device}\")\n",
    "\n",
    "# Get the actual number of channels from the tensor\n",
    "channels = dummy_tensor.shape[0]\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(50*50*input_channels, 512),  #\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(channels)\n",
    "#print(model)\n",
    "\n",
    "# Add batch dimension for the model\n",
    "input_tensor = dummy_tensor.unsqueeze(0)\n",
    "logits = model(input_tensor)\n",
    "print(f\"Input->Output:   {dummy_tensor.shape}->{logits.shape}\")\n",
    "print(f\"Output logits: {logits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03532a7b-e35a-41bf-a1de-7a9955a33c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizeOfImage: 50x50\n",
      "Shape of tensor: torch.Size([4, 50, 50])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([10000])\n",
      "Datatype of tensor: torch.float32\n",
      "Input shape: torch.Size([10000])\n",
      "After layer 1 (Linear): torch.Size([1000])\n",
      "After layer 2 (ReLU): torch.Size([1000])\n",
      "After layer 3 (Linear): torch.Size([100])\n",
      "After layer 4 (ReLU): torch.Size([100])\n",
      "After layer 5 (Linear): torch.Size([10])\n",
      "After layer 6 (ReLU): torch.Size([10])\n",
      "After layer 7 (Dropout): torch.Size([10])\n",
      "tensor([0.0986, 0.0000, 0.0473, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0675,\n",
      "        0.0000], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Simple Sequential\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the image and convert to proper tensor format\n",
    "image = Image.open('magic_lamp.png')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((50, 50)),  # Ensure 50x50 size\n",
    "    transforms.ToTensor()  # Converts to float32\n",
    "])\n",
    "dummy_tensor = transform(image)\n",
    "input_tensor = dummy_tensor.flatten()\n",
    "\n",
    "print(f\"sizeOfImage: 50x50\")\n",
    "print(f\"Shape of tensor: {dummy_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {dummy_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {input_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {input_tensor.dtype}\")\n",
    "#print(f\"Device tensor is stored on: {dummy_tensor.device}\")\n",
    "\n",
    "model_sequential = nn.Sequential(\n",
    "    nn.Linear(10000, 1000),  \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000, 100),            \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10),        \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),  #randomly sets some neurnons to zero\n",
    ")\n",
    "\n",
    "# Debug function to see shapes at each layer\n",
    "def debug_sequential_shapes(model, input_tensor):\n",
    "    x = input_tensor\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    \n",
    "    for i, layer in enumerate(model):\n",
    "        x = layer(x)\n",
    "        print(f\"After layer {i+1} ({layer.__class__.__name__}): {x.shape}\")\n",
    "    \n",
    "    return x\n",
    "print(debug_sequential_shapes(model_sequential,input_tensor))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f857a7-6ff9-4f3f-ae34-58df1b63d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.Linear(3, 2) - Fully Connected Layer\n",
      "Description: Applies linear transformation with learnable weights and bias\n",
      "Use case: Classification heads, feature transformation\n",
      "Input : torch.Size([1, 3])\n",
      "Output: torch.Size([1, 2])\n",
      "\n",
      "nn.Conv2d(in_channels=4, out_channels=6, kernel_size=5)\n",
      "Description: Applies 2D convolution with 6 filters of size 5x5\n",
      "Use case: Feature extraction in images, CNNs\n",
      "Input : torch.Size([1, 4, 32, 32])\n",
      "Output: torch.Size([1, 6, 28, 28])\n",
      "\n",
      "nn.MaxPool2d(kernel_size=2, stride=2)\n",
      "Description: Downsamples by taking max value in 2x2 windows\n",
      "Use case: Reducing spatial dimensions, translation invariance\n",
      "Input : torch.Size([1, 3, 28, 28])\n",
      "Output: torch.Size([1, 3, 14, 14])\n",
      "\n",
      "nn.BatchNorm2d(3)\n",
      "Description: Normalizes activations across batch dimension\n",
      "Use case: Stabilizing training, faster convergence\n",
      "Input : torch.Size([4, 3, 16, 16])\n",
      "Output: torch.Size([4, 3, 16, 16])\n",
      "\n",
      "nn.Dropout(p=0.5)\n",
      "Description: Randomly zeros 50% of input elements during training\n",
      "Use case: Regularization, preventing overfitting\n",
      "Input : torch.Size([2, 10])\n",
      "Output: torch.Size([2, 10])\n",
      "\n",
      "nn.LSTM(input_size=10, hidden_size=20, num_layers=2)\n",
      "Description: Processes sequences with memory cells and gates\n",
      "Use case: NLP, time series, any sequential data\n",
      "Input : torch.Size([3, 5, 10])\n",
      "Output: torch.Size([3, 5, 20])\n",
      "Hidden: torch.Size([2, 3, 20])\n",
      "Cell  : torch.Size([2, 3, 20])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. LINEAR LAYER\n",
    "# Applies a linear transformation: y = xW^T + b\n",
    "# Commonly used as the final layer in classifiers or for dimensionality changes\n",
    "linear = nn.Linear(3, 2)  # Maps 3 features to 2 features\n",
    "x = torch.tensor([[1.0, 2.0, 3.0]])\n",
    "output = linear(x)\n",
    "print(\"nn.Linear(3, 2) - Fully Connected Layer\")\n",
    "print(\"Description: Applies linear transformation with learnable weights and bias\")\n",
    "print(\"Use case: Classification heads, feature transformation\")\n",
    "print(\"Input :\", x.shape)  # torch.Size([1, 3])\n",
    "print(\"Output:\", output.shape)  # torch.Size([1, 2])\n",
    "print()\n",
    "\n",
    "# 2. 2D CONVOLUTIONAL LAYER\n",
    "# Applies 2D convolution operation using learnable filters/kernels\n",
    "# Essential for computer vision tasks to detect features like edges, textures\n",
    "conv = nn.Conv2d(in_channels=4, out_channels=6, kernel_size=5)\n",
    "x = torch.randn(1, 4, 32, 32)  # Batch=1, Channels=4, Height=32, Width=32\n",
    "output = conv(x)\n",
    "print(\"nn.Conv2d(in_channels=4, out_channels=6, kernel_size=5)\")\n",
    "print(\"Description: Applies 2D convolution with 6 filters of size 5x5\")\n",
    "print(\"Use case: Feature extraction in images, CNNs\")\n",
    "print(\"Input :\", x.shape)  # torch.Size([1, 4, 32, 32])\n",
    "print(\"Output:\", output.shape)  # torch.Size([1, 6, 28, 28])\n",
    "print()\n",
    "\n",
    "# 3. MAX POOLING LAYER\n",
    "# Downsamples by taking the maximum value in each pooling window\n",
    "# Reduces spatial dimensions while retaining important features\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "x = torch.randn(1, 3, 28, 28)\n",
    "output = maxpool(x)\n",
    "print(\"nn.MaxPool2d(kernel_size=2, stride=2)\")\n",
    "print(\"Description: Downsamples by taking max value in 2x2 windows\")\n",
    "print(\"Use case: Reducing spatial dimensions, translation invariance\")\n",
    "print(\"Input :\", x.shape)  # torch.Size([1, 3, 28, 28])\n",
    "print(\"Output:\", output.shape)  # torch.Size([1, 3, 14, 14])\n",
    "print()\n",
    "\n",
    "# 4. BATCH NORMALIZATION LAYER\n",
    "# Normalizes inputs by adjusting and scaling activations\n",
    "# Accelerates training and provides regularization effect\n",
    "batchnorm = nn.BatchNorm2d(3)  # 3 channels to normalize\n",
    "x = torch.randn(4, 3, 16, 16)  # Batch of 4 images\n",
    "output = batchnorm(x)\n",
    "print(\"nn.BatchNorm2d(3)\")\n",
    "print(\"Description: Normalizes activations across batch dimension\")\n",
    "print(\"Use case: Stabilizing training, faster convergence\")\n",
    "print(\"Input :\", x.shape)  # torch.Size([4, 3, 16, 16])\n",
    "print(\"Output:\", output.shape)  # torch.Size([4, 3, 16, 16])\n",
    "print()\n",
    "\n",
    "# 5. DROPOUT LAYER\n",
    "# Randomly sets input elements to zero during training\n",
    "# Prevents overfitting by forcing network to not rely on specific neurons\n",
    "dropout = nn.Dropout(p=0.5)  # 50% probability of zeroing elements\n",
    "x = torch.randn(2, 10)\n",
    "output = dropout(x)\n",
    "print(\"nn.Dropout(p=0.5)\")\n",
    "print(\"Description: Randomly zeros 50% of input elements during training\")\n",
    "print(\"Use case: Regularization, preventing overfitting\")\n",
    "print(\"Input :\", x.shape)  # torch.Size([2, 10])\n",
    "print(\"Output:\", output.shape)  # torch.Size([2, 10])\n",
    "print()\n",
    "\n",
    "# 6. LSTM LAYER\n",
    "# Long Short-Term Memory - processes sequential data with memory cells\n",
    "# Can capture long-term dependencies in sequences\n",
    "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "x = torch.randn(3, 5, 10)  # Batch=3, Sequence=5, Features=10\n",
    "output, (h_n, c_n) = lstm(x)\n",
    "print(\"nn.LSTM(input_size=10, hidden_size=20, num_layers=2)\")\n",
    "print(\"Description: Processes sequences with memory cells and gates\")\n",
    "print(\"Use case: NLP, time series, any sequential data\")\n",
    "print(\"Input :\", x.shape)  # torch.Size([3, 5, 10])\n",
    "print(\"Output:\", output.shape)  # torch.Size([3, 5, 20])\n",
    "print(\"Hidden:\", h_n.shape)  # torch.Size([2, 3, 20])\n",
    "print(\"Cell  :\", c_n.shape)  # torch.Size([2, 3, 20])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5fdedc-b4cc-4677-8603-0bdc24f7276b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad8eb9-19ec-4bad-8382-ea2a5c8f2e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
